import time
import pandas as pd
import requests
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

def get_lat_lng_from_address(address, api_key):
    url = 'https://dapi.kakao.com/v2/local/search/address.json'
    headers = {"Authorization": f"KakaoAK {api_key}"}
    params = {"query": address}

    response = requests.get(url, headers=headers, params=params)
    
    if response.status_code == 200:
        result = response.json()
        if not result['documents']:
            print(f"âŒ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨ â†’ '{address}'")
        else:
            location = result['documents'][0]['address']
            return location['y'], location['x']
    else:
        print(f"âŒ API ì˜¤ë¥˜ ({response.status_code}): {response.text}")
    return None, None


# ë°”ë‚˜í”„ë ˆì†Œ í¬ë¡¤ë§ í•¨ìˆ˜
def fetch_bana(api_key):
    bana_url = 'https://www.banapresso.com/'
    driver = webdriver.Chrome()
    driver.get(bana_url)
    time.sleep(1)

    # ë§¤ì¥ì°¾ê¸° ë©”ë‰´ í´ë¦­
    driver.find_element(By.XPATH, '/html/body/div/div/article/div[1]/div/a[1]/div').click()
    time.sleep(2)

    # ë©”ë‰´ > ë§¤ì¥ì°¾ê¸° ì´ë™
    # âœ… hover â†’ click êµ¬ì¡°
    action = ActionChains(driver)

    store_menu = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, '#wrap > header > div > ul > li:nth-child(3) > a'))
    )

    store_search_menu = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, '#wrap > header > div > ul > li:nth-child(3) > ul > li:nth-child(1) > a'))
    )

    action.move_to_element(store_menu).move_to_element(store_search_menu).click().perform()
    time.sleep(2)


    # ë§¤ì¥ ë¦¬ìŠ¤íŠ¸ ë¡œë”© ëŒ€ê¸°
    scrollable_div = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, '.store_shop_list'))
    )
    time.sleep(1)

    # ìŠ¤í¬ë¡¤ ë°˜ë³µ
    for _ in range(20):
        driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scrollable_div)
        time.sleep(1)

    # HTML íŒŒì‹±
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    store_items = soup.select('.store_shop_list > ul > li')

    print(f"ğŸ“¦ ì´ ë§¤ì¥ ìˆ˜: {len(store_items)}")

    results = []
    for item in store_items:
        name_tag = item.select_one('a > span > i')
        addr_tag = item.select_one('a > span > span')

        store_name = name_tag.text.strip() if name_tag else ''
        store_addr = addr_tag.text.strip() if addr_tag else ''

        lat, lng = get_lat_lng_from_address(store_addr, api_key)

        print(f"ğŸ“ {store_name} - {store_addr} â†’ ìœ„ë„: {lat}, ê²½ë„: {lng}")

        results.append({
            'ë§¤ì¥ëª…': store_name,
            'ì£¼ì†Œ': store_addr,
            'ìœ„ë„': lat,
            'ê²½ë„': lng
        })

    driver.quit()

    # DataFrame ì €ì¥
    df = pd.DataFrame(results)
    csv_path = os.path.join(os.getcwd(), 'banapresso_stores.csv')
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… CSV ì €ì¥ ì™„ë£Œ!\nğŸ“ íŒŒì¼ ìœ„ì¹˜: {csv_path}\nğŸ“„ ì´ ë§¤ì¥ ìˆ˜: {len(df)}ê°œ")
fetch_bana('9cda7248ae6173da152c629e811dad49')